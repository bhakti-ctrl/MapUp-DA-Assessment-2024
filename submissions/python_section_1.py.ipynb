{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b441d983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 6, 5, 4, 8, 7]\n",
      "[2, 1, 4, 3, 5]\n",
      "[40, 30, 20, 10, 70, 60, 50]\n",
      "{3: ['bat', 'car', 'dog'], 4: ['bear'], 5: ['apple'], 8: ['elephant']}\n",
      "{3: ['one', 'two'], 4: ['four'], 5: ['three']}\n",
      "{'road.name': 'Highway 1', 'road.length': 350, 'road.sections[0].id': 1, 'road.sections[0].condition.pavement': 'good', 'road.sections[0].condition.traffic': 'moderate'}\n",
      "[[1, 1, 2], [1, 2, 1], [2, 1, 1]]\n",
      "['23-08-1994', '08/23/1994', '1994.08.23']\n",
      "Requirement already satisfied: polyline in c:\\users\\home\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "   latitude  longitude       distance\n",
      "0  38.50000 -120.20000       0.000000\n",
      "1  40.70000 -120.21824  244633.828322\n",
      "2  40.69345 -120.22031     748.941904\n",
      "3  40.68754 -120.22015     657.300462\n",
      "4  40.68782 -120.21987      39.073342\n",
      "5  40.68796 -120.21967      22.950123\n",
      "6  40.68824 -120.21953      33.297166\n",
      "7  40.68844 -120.21937      26.010869\n",
      "[14, 4, 0]\n",
      "[24, 10, 2]\n",
      "[36, 18, 6]\n",
      "Dataset loaded successfully.\n",
      "Columns in the DataFrame: ['id', 'name', 'id_2', 'startDay', 'startTime', 'endDay', 'endTime', 'able2Hov2', 'able2Hov3', 'able3Hov2', 'able3Hov3', 'able5Hov2', 'able5Hov3', 'able4Hov2', 'able4Hov3']\n",
      "Initial DataFrame:\n",
      "   startDay startTime     endDay   endTime\n",
      "0    Monday   5:00:00  Wednesday  10:00:00\n",
      "1    Monday  10:00:00     Friday  15:00:00\n",
      "2  Thursday  15:00:00     Friday  19:00:00\n",
      "3    Monday  19:00:00     Friday  23:59:59\n",
      "4  Saturday   0:00:00     Sunday  23:59:59\n",
      "5    Monday   0:00:00     Friday   5:00:00\n",
      "6    Monday   5:00:00     Friday  10:00:00\n",
      "7    Monday  10:00:00     Friday  15:00:00\n",
      "8   Tuesday  15:00:00   Saturday  19:00:00\n",
      "9    Monday  15:00:00     Friday  19:00:00\n",
      "Complete Groups:\n",
      "id       id_2    \n",
      "1030000   1030020    True\n",
      "          1030022    True\n",
      "          1030044    True\n",
      "          1030048    True\n",
      "          1030052    True\n",
      "                     ... \n",
      "1165005  -1          True\n",
      "1165006  -1          True\n",
      "1165007  -1          True\n",
      "1165008  -1          True\n",
      "1165009  -1          True\n",
      "Length: 358, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Reverses the input list by groups of n elements.\n",
    "    \"\"\"\n",
    "    result = []  # To hold the final result\n",
    "    length = len(lst)\n",
    "    \n",
    "    for i in range(0, length, n):\n",
    "        # Create a temporary list for the current group\n",
    "        group = []\n",
    "        \n",
    "        # Collect the current group elements\n",
    "        for j in range(i, min(i + n, length)):\n",
    "            group.append(lst[j])\n",
    "        \n",
    "        # Manually reverse the current group and add to result\n",
    "        for j in range(len(group) - 1, -1, -1):\n",
    "            result.append(group[j])\n",
    "    return result\n",
    "\n",
    "    return lst\n",
    "#OUTPUT 1\n",
    "if __name__ == \"__main__\":\n",
    "    print(reverse_by_n_elements([1, 2, 3, 4, 5, 6, 7, 8], 3)) \n",
    "    print(reverse_by_n_elements([1, 2, 3, 4, 5], 2))         \n",
    "    print(reverse_by_n_elements([10, 20, 30, 40, 50, 60, 70], 4)) \n",
    "    \n",
    "    \n",
    " #Question 2   \n",
    "def group_by_length(lst: List[str]) -> Dict[int, List[str]]:\n",
    "    \"\"\"\n",
    "    Groups the strings by their length and returns a dictionary.\n",
    "    \"\"\"\n",
    "    from typing import List, Dict\n",
    "\n",
    "    length_dict = {}  # Initialize an empty dictionary to hold the grouped strings\n",
    "\n",
    "    for string in lst:\n",
    "        length = len(string)  # Get the length of the string\n",
    "        if length not in length_dict:\n",
    "            length_dict[length] = []  # Initialize a list if this length key doesn't exist\n",
    "        length_dict[length].append(string)  # Append the string to the correspond length list\n",
    "    \n",
    "    # Sort the dictionary by keys and return it\n",
    "    return dict(sorted(length_dict.items()))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(group_by_length([\"apple\", \"bat\", \"car\", \"elephant\", \"dog\", \"bear\"]))  \n",
    "    \n",
    "    print(group_by_length([\"one\", \"two\", \"three\", \"four\"]))  \n",
    "    \n",
    "    \n",
    "#Question 3\n",
    "from typing import Dict, Any\n",
    "\n",
    "def flatten_dict(nested_dict: Dict[str, Any], sep: str = '.') -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Flattens a nested dictionary into a single-level dictionary with dot notation for keys,\n",
    "    and handles lists by including their indices in square brackets.\n",
    "    \n",
    "    :param nested_dict: The dictionary object to flatten\n",
    "    :param sep: The separator to use between parent and child keys (defaults to '.')\n",
    "    :return: A flattened dictionary\n",
    "    \"\"\"\n",
    "    flattened_dict = {}\n",
    "\n",
    "    def flatten(current_dict: Dict[str, Any], parent_key: str = ''):\n",
    "        for key, value in current_dict.items():\n",
    "            # Construct new key\n",
    "            new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n",
    "            \n",
    "            if isinstance(value, dict):\n",
    "                # If the value is a dictionary, recurse into it\n",
    "                flatten(value, new_key)\n",
    "            elif isinstance(value, list):\n",
    "                # If the value is a list, iterate through its elements\n",
    "                for index, item in enumerate(value):\n",
    "                    # Create a new key with the index\n",
    "                    list_key = f\"{new_key}[{index}]\"\n",
    "                    if isinstance(item, dict):\n",
    "                        flatten(item, list_key)  # Recurse for nested dictionaries in the list\n",
    "                    else:\n",
    "                        flattened_dict[list_key] = item\n",
    "            else:\n",
    "                # Assign the value to the new key in the flattened dictionary\n",
    "                flattened_dict[new_key] = value\n",
    "\n",
    "    flatten(nested_dict)  # Start the flattening process\n",
    "    return flattened_dict\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    nested = {\n",
    "        \"road\": {\n",
    "            \"name\": \"Highway 1\",\n",
    "            \"length\": 350,\n",
    "            \"sections\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"condition\": {\n",
    "                        \"pavement\": \"good\",\n",
    "                        \"traffic\": \"moderate\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    flattened = flatten_dict(nested)\n",
    "    print(flattened)\n",
    "    \n",
    "#Question 4\n",
    "from typing import List\n",
    "\n",
    "def unique_permutations(nums: List[int]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Generate all unique permutations of a list that may contain duplicates.\n",
    "    \n",
    "    :param nums: List of integers (may contain duplicates)\n",
    "    :return: List of unique permutations\n",
    "    \"\"\"\n",
    "    def backtrack(start: int):\n",
    "        if start == len(nums):\n",
    "            # Found a valid permutation\n",
    "            result.append(nums[:])  # Append a copy of the current permutation\n",
    "            return\n",
    "        \n",
    "        seen = set()  # To track seen numbers at this level\n",
    "        for i in range(start, len(nums)):\n",
    "            if nums[i] in seen:\n",
    "                continue  # Skip duplicates\n",
    "            seen.add(nums[i])\n",
    "            # Swap the current element with the start\n",
    "            nums[start], nums[i] = nums[i], nums[start]\n",
    "            # Recurse with the next index\n",
    "            backtrack(start + 1)\n",
    "            # Swap back to restore the original list\n",
    "            nums[start], nums[i] = nums[i], nums[start]\n",
    "\n",
    "    result = []\n",
    "    nums.sort()  # Sort the numbers to handle duplicates\n",
    "    backtrack(0)  # Start generating permutations\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_list = [1, 1, 2]\n",
    "    result = unique_permutations(input_list)\n",
    "    print(result)\n",
    "    \n",
    "#Question 5\n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def find_all_dates(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function takes a string as input and returns a list of valid dates\n",
    "    in 'dd-mm-yyyy', 'mm/dd/yyyy', or 'yyyy.mm.dd' format found in the string.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): A string containing the dates in various formats.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of valid dates in the formats specified.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to match the date formats\n",
    "    date_pattern = r'\\b(\\d{2}-\\d{2}-\\d{4}|\\d{2}/\\d{2}/\\d{4}|\\d{4}\\.\\d{2}\\.\\d{2})\\b'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(date_pattern, text)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23.\"\n",
    "    result = find_all_dates(text)\n",
    "    print(result)\n",
    "    \n",
    "    \n",
    "#Question 6\n",
    "!pip install polyline\n",
    "import pandas as pd\n",
    "import polyline\n",
    "import numpy as np\n",
    "\n",
    "def haversine(coord1, coord2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points on the Earth specified in decimal degrees\n",
    "    using the Haversine formula.\n",
    "\n",
    "    :param coord1: Tuple (latitude1, longitude1)\n",
    "    :param coord2: Tuple (latitude2, longitude2)\n",
    "    :return: Distance in meters\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1 = np.radians(coord1)\n",
    "    lat2, lon2 = np.radians(coord2)\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # Radius of Earth in meters\n",
    "    radius = 6371000\n",
    "    distance = radius * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a polyline string into a DataFrame with latitude, longitude, and distance between consecutive points.\n",
    "    \n",
    "    Args:\n",
    "        polyline_str (str): The encoded polyline string.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.\n",
    "    \"\"\"\n",
    "    # Decode the polyline string into a list of coordinates\n",
    "    decoded_coords = polyline.decode(polyline_str)\n",
    "\n",
    "    # Create lists to store latitude, longitude, and distances\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    distances = [0]  # Initialize the first distance as 0\n",
    "\n",
    "    # Calculate distances between consecutive coordinates\n",
    "    for i in range(len(decoded_coords)):\n",
    "        latitudes.append(decoded_coords[i][0])\n",
    "        longitudes.append(decoded_coords[i][1])\n",
    "        \n",
    "        if i > 0:  # For all but the first coordinate\n",
    "            distance = haversine(decoded_coords[i - 1], decoded_coords[i])\n",
    "            distances.append(distance)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'latitude': latitudes,\n",
    "        'longitude': longitudes,\n",
    "        'distance': distances\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    polyline_str = \"_p~iF~ps|U_ulL~pB|g@|K|c@_@w@w@[g@w@[g@_@\"\n",
    "    df = polyline_to_dataframe(polyline_str)\n",
    "    print(df)\n",
    "\n",
    "    \n",
    "#Question 7\n",
    "from typing import List\n",
    "\n",
    "def rotate_and_multiply_matrix(matrix: List[List[int]]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Rotate the given matrix by 90 degrees clockwise, then multiply each element \n",
    "    by the sum of its original row and column index before rotation.\n",
    "    \n",
    "    Args:\n",
    "    - matrix (List[List[int]]): 2D list representing the matrix to be transformed.\n",
    "    \n",
    "    Returns:\n",
    "    - List[List[int]]: A new 2D list representing the transformed matrix.\n",
    "    \"\"\"\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # Step 1: Rotate the matrix 90 degrees clockwise\n",
    "    rotated_matrix = [[matrix[n - j - 1][i] for j in range(n)] for i in range(n)]\n",
    "    \n",
    "    # Step 2: Create a new matrix for the transformed values\n",
    "    transformed_matrix = [[0] * n for _ in range(n)]\n",
    "    \n",
    "    # Step 3: Populate the transformed matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            original_row_index = n - j - 1\n",
    "            original_col_index = i\n",
    "            # Multiply by the sum of original row and column indices\n",
    "            transformed_matrix[i][j] = rotated_matrix[i][j] * (original_row_index + original_col_index)\n",
    "\n",
    "    return transformed_matrix\n",
    "\n",
    "# Example usage\n",
    "matrix = [[1, 2, 3], \n",
    "          [4, 5, 6], \n",
    "          [7, 8, 9]]\n",
    "\n",
    "result = rotate_and_multiply_matrix(matrix)\n",
    "for row in result:\n",
    "    print(row)\n",
    "\n",
    "#Question 8\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset(file_path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', encoding='ISO-8859-1', engine='python')\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the dataset: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def time_check(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Print the relevant columns for debugging\n",
    "    print(\"Initial DataFrame:\")\n",
    "    print(df[['startDay', 'startTime', 'endDay', 'endTime']].head(10))\n",
    "\n",
    "    # Mapping days to a standard date\n",
    "    day_to_date = {\n",
    "        'Monday': '2023-01-02',\n",
    "        'Tuesday': '2023-01-03',\n",
    "        'Wednesday': '2023-01-04',\n",
    "        'Thursday': '2023-01-05',\n",
    "        'Friday': '2023-01-06',\n",
    "        'Saturday': '2023-01-07',\n",
    "        'Sunday': '2023-01-08'\n",
    "    }\n",
    "    \n",
    "    # Replace days with corresponding dates\n",
    "    df['start_date'] = df['startDay'].map(day_to_date)\n",
    "    df['end_date'] = df['endDay'].map(day_to_date)\n",
    "\n",
    "    # Create datetime strings\n",
    "    df['start'] = pd.to_datetime(df['start_date'] + ' ' + df['startTime'], errors='coerce')\n",
    "    df['end'] = pd.to_datetime(df['end_date'] + ' ' + df['endTime'], errors='coerce')\n",
    "    \n",
    "    return df  # Return the updated DataFrame\n",
    "\n",
    "def validate_completeness(group):\n",
    "    # Extract start and end dates\n",
    "    start_dates = group['start'].dt.date.unique()\n",
    "    end_dates = group['end'].dt.date.unique()\n",
    "    \n",
    "    # Collect the days covered\n",
    "    covered_days = set()\n",
    "    \n",
    "    for start in start_dates:\n",
    "        covered_days.add(pd.to_datetime(start).dayofweek)  # 0=Mon, 1=Tue, ..., 6=Sun\n",
    "    \n",
    "    for end in end_dates:\n",
    "        covered_days.add(pd.to_datetime(end).dayofweek)\n",
    "\n",
    "    # Check if covered days match all days (0 to 6)\n",
    "    is_complete = covered_days == {0, 1, 2, 3, 4, 5, 6}\n",
    "    \n",
    "    # Check the duration\n",
    "    duration_check = (group['end'].max() - group['start'].min()).days >= 6\n",
    "\n",
    "    return is_complete and duration_check\n",
    "\n",
    "# Load dataset and check column names\n",
    "df = load_dataset('C:/Users/Home/Downloads/dataset-1.csv')\n",
    "print(\"Columns in the DataFrame:\", df.columns.tolist())\n",
    "\n",
    "# Ensure that 'id' and 'id_2' columns are present\n",
    "if 'id' in df.columns and 'id_2' in df.columns:\n",
    "    df = time_check(df)  # Update df with time information\n",
    "    result_series = df.groupby(['id', 'id_2']).apply(validate_completeness)\n",
    "\n",
    "    # Filter the results for complete groups\n",
    "    complete_groups = result_series[result_series == True]\n",
    "\n",
    "    # Print the complete groups\n",
    "    print(\"Complete Groups:\")\n",
    "    print(complete_groups)\n",
    "else:\n",
    "    print(\"Columns 'id' and/or 'id_2' are missing from the DataFrame.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82195d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_start  distance\n",
      "0         1      99.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample distance matrix creation\n",
    "def create_distance_matrix(data):\n",
    "    \"\"\"Creates a sample distance matrix as a DataFrame.\"\"\"\n",
    "    distances = []\n",
    "    for i in data['id_start']:\n",
    "        for j in data['id_end']:\n",
    "            if i != j:\n",
    "                distance = np.random.randint(1, 100)  # Random distances for demonstration\n",
    "                distances.append((i, j, distance))\n",
    "    return pd.DataFrame(distances, columns=['id_start', 'id_end', 'distance'])\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'id_start': [1, 1, 2, 2],\n",
    "    'id_end': [2, 3, 1, 3]\n",
    "})\n",
    "\n",
    "# Create the distance matrix\n",
    "distance_df = create_distance_matrix(data)\n",
    "\n",
    "# Unroll distance matrix\n",
    "def unroll_distance_matrix(df) -> pd.DataFrame:\n",
    "    \"\"\"Unroll a distance matrix to a DataFrame.\"\"\"\n",
    "    unrolled = []\n",
    "    unique_ids = df['id_start'].unique()\n",
    "    for id_start in unique_ids:\n",
    "        for id_end in unique_ids:\n",
    "            if id_start != id_end:\n",
    "                distance = df.loc[(df['id_start'] == id_start) & (df['id_end'] == id_end), 'distance'].values\n",
    "                if distance.size > 0:\n",
    "                    unrolled.append((id_start, id_end, distance[0]))\n",
    "    return pd.DataFrame(unrolled, columns=['id_start', 'id_end', 'distance'])\n",
    "\n",
    "# Unroll the distance matrix\n",
    "unrolled_df = unroll_distance_matrix(distance_df)\n",
    "\n",
    "# Find IDs within the 10% threshold\n",
    "def find_ids_within_ten_percentage_threshold(df: pd.DataFrame, reference_id: int) -> pd.DataFrame:\n",
    "    \"\"\"Find all IDs whose average distance lies within 10% of the average distance of the reference ID.\"\"\"\n",
    "    reference_avg = df[df['id_start'] == reference_id]['distance'].mean()\n",
    "    \n",
    "    lower_bound = reference_avg * 0.9\n",
    "    upper_bound = reference_avg * 1.1\n",
    "\n",
    "    avg_distances = df.groupby('id_start')['distance'].mean().reset_index()\n",
    "\n",
    "    filtered_ids = avg_distances[\n",
    "        (avg_distances['distance'] >= lower_bound) & \n",
    "        (avg_distances['distance'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    sorted_filtered_ids = filtered_ids.sort_values(by='distance')\n",
    "\n",
    "    return sorted_filtered_ids\n",
    "\n",
    "# Example usage with a reference ID\n",
    "reference_id = 1  # Change this as needed\n",
    "result_df = find_ids_within_ten_percentage_threshold(unrolled_df, reference_id)\n",
    "\n",
    "# Print the result\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d54e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
